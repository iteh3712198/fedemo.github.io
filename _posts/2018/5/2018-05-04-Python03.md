---
layout:     post
title:      Python图片爬虫
subtitle:   Python code
date:       2018-05-04
author:     Tao
header-img: img/home-bg-o.jpg
keywords_post:  "github,Python,图片爬虫,淘宝"
catalog: true
tags:
    - Python
    - 图片爬虫
---
# 图片爬虫的测试
>这里对淘网宝的进行图片爬虫的测试，观察网址的区别

```
https://s.taobao.com/search?q=%E9%94%AE%E7%9B%98&imgfile=&commend=all&ssid=s5-e&search_type=item&sourceId=tb.index&spm=a21bo.2017.201856-taobao-item.1&ie=utf8&initiative_id=tbindexz_20170306&p4ppushleft=5%2C48&s=0
```
这是搜索默认第一页的网址

```
https://s.taobao.com/search?q=%E9%94%AE%E7%9B%98&imgfile=&commend=all&ssid=s5-e&search_type=item&sourceId=tb.index&spm=a21bo.2017.201856-taobao-item.1&ie=utf8&initiative_id=tbindexz_20170306&p4ppushleft=5%2C48&s=48

```
这是搜索第二页的网址

```
https://s.taobao.com/search?q=%E9%94%AE%E7%9B%98&imgfile=&commend=all&ssid=s5-e&search_type=item&sourceId=tb.index&spm=a21bo.2017.201856-taobao-item.1&ie=utf8&initiative_id=tbindexz_20170306&p4ppushleft=5%2C48&s=96

```
这是搜索第三页的网址

1. 观察到除第一页外S=X这个值每次以48的数值递增，只改变这个数值去访问的时候发现页数也跟着变化了，确定应该是由这个数值来控制翻页,q=为关键字（中文关键字需要进行编码）
2. 实验过程中发现如果爬取天猫的网页需要模拟登陆，解决302错误，这里先对淘宝进行爬取
3. 观察网页的源码，发现大图在"pic-url"之后，使用正则表达是抓取然后组装图片地址用于下载

```
pic_url":"//g-search1.alicdn.com/img/bao/uploaded/i4/TB14Ua_LXXXXXbIXVXXlTEz9pXX_042354.jpg
```
4. 此处希望以爬取图片对应的名字对下载的文件进行命名，同时也需要匹配出对应的图片名字
5. 爬取时发现编码出错，这里修改了系统的编码格式为utf-8

```
keyname = "键盘"
#中文进行编码
key = urllib.request.quote(keyname)
#爬取10页的图片
for j in range(0, 11):
    # 组装请求的字符串
    url = "https://s.taobao.com/search?q="+key+"&imgfile=&commend=all&ssid=s5-e&search_type=item&sourceId" \
          "=tb.index&spm=a21bo.2017.201856-taobao-item.1&ie=utf8&initiative_id=tbindexz_20170306&p4ppushleft=5%2C48&s="+str(j*48)
    data = urllib.request.urlopen(url).read().decode("utf-8", "ignore")
    # 正则匹配图片的地址
    pat = "\"title\":\"(.*?)\".*?pic_url\":\"//(.*?)\""
    rs = re.compile(pat).findall(data)
    for i in range(0, len(rs)):
        # 组装保存的文件路径,替换掉其中的斜杠
        fileName = rs[i][0].replace("/", "&")
        file = "D:/test/taobao/" + fileName + ".jpg"
        print(fileName)
        # 将文件下载到本地
        imgUrl = "https://" + rs[i][1]
        print(imgUrl)
        try:
            urllib.request.urlretrieve(imgUrl, file)
        except urllib.error.URLError as error:
            if hasattr(error, "code"):
                print(error.code)
            if hasattr(error, "reason"):
                print(error.reason)
```
![键盘](https://raw.githubusercontent.com/iteh3712198/iteh3712198.github.io/master/img/2018/taobao01.png)
